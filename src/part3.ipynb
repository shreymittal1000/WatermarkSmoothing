{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abJuxKOhHh66",
        "outputId": "3049366e-5d16-4aba-c382-6243dad1ba28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate==0.34.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 1)) (0.34.2)\n",
            "Requirement already satisfied: huggingface_hub==0.24.6 in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 2)) (0.24.6)\n",
            "Requirement already satisfied: torch==2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 3)) (2.4.1+cu121)\n",
            "Requirement already satisfied: transformers==4.44.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 4)) (4.44.2)\n",
            "Requirement already satisfied: urllib3<2 in /usr/local/lib/python3.10/dist-packages (from -r /content/requirements.txt (line 5)) (1.26.20)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->-r /content/requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->-r /content/requirements.txt (line 1)) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->-r /content/requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->-r /content/requirements.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.34.2->-r /content/requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->-r /content/requirements.txt (line 3)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->-r /content/requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.4.1->-r /content/requirements.txt (line 3)) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2->-r /content/requirements.txt (line 4)) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.44.2->-r /content/requirements.txt (line 4)) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.4.1->-r /content/requirements.txt (line 3)) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub==0.24.6->-r /content/requirements.txt (line 2)) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.4.1->-r /content/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        " !pip3 install -r /content/requirements.txt\n",
        " !pip3 install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (pipeline, AutoTokenizer, AutoModelForCausalLM)\n",
        "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tools import tensor_rank_positions, rank_difference, n_smaller, z_score\n",
        "from watermark_tools_context_independent import (\n",
        "    generate_soft_greenlist_watermark_context_independent, watermark_checker, predict_greenlist_confidence, smoothed_logits\n",
        ")\n",
        "\n",
        "import os\n",
        "import transformers\n",
        "from huggingface_hub import login\n",
        "import bitsandbytes as bnb\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_Y0zvp5KHmBY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_id: str):\n",
        "    # Set Hugging Face Hub token\n",
        "    hf_token = \"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\"\n",
        "\n",
        "    # Manually login with the token\n",
        "    login(token=hf_token)\n",
        "\n",
        "    if os.path.exists(model_id):\n",
        "        local_dir = \"./\" + model_id\n",
        "        tokenizer = AutoTokenizer.from_pretrained(local_dir)\n",
        "        model = AutoModelForCausalLM.from_pretrained(local_dir, device_map=\"auto\", load_in_8bit=True)\n",
        "        return model, tokenizer\n",
        "    else:\n",
        "        print(f\"Model {model_id} not found locally. Downloading and caching/...\")\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_id,\n",
        "            device_map=\"auto\",\n",
        "            load_in_8bit=True,\n",
        "        )\n",
        "        model.save_pretrained(model_id)\n",
        "        tokenizer.save_pretrained(model_id)\n",
        "        return model, tokenizer"
      ],
      "metadata": {
        "id": "yDFfr0HlHpVX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranks_small = torch.load('ranks_small.pt')\n",
        "ranks_large = torch.load('ranks_big.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjRqxkwpHs0S",
        "outputId": "cccdc33d-3bf5-4fdf-9403-da8c36bb16c4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-9d8467c9f439>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ranks_small = torch.load('ranks_small.pt')\n",
            "<ipython-input-5-9d8467c9f439>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  ranks_large = torch.load('ranks_big.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ranks_small.shape)\n",
        "print(ranks_large.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy61u5NnHxRW",
        "outputId": "0e294c43-f20a-4929-e17a-f1315be1e628"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([30, 32000])\n",
            "torch.Size([30, 32000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank_diff = rank_difference(ranks_large, ranks_small)\n",
        "print(rank_diff)\n",
        "\n",
        "confidence = predict_greenlist_confidence(ranks_large, ranks_small)\n",
        "print(confidence)\n",
        "print(torch.max(confidence))\n",
        "print(torch.min(confidence))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1I6_Jb4eI0C5",
        "outputId": "1912f971-3de0-49c5-e783-832e4f28d3fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5314,    -8, 21325,  ...,   -23,   -23,   -23],\n",
            "        [ 5301,   -14,   -14,  ...,   -28,   -28,   -28],\n",
            "        [ 5301,   -14,   -14,  ...,   -29,   -29,   -29],\n",
            "        ...,\n",
            "        [  -26,   -13, 21325,  ...,   -29,   -29,   -29],\n",
            "        [  -28,   -15, 21299,  ...,   -29,   -29,   -29],\n",
            "        [ 5301,   -13, 21325,  ...,   -27,   -27,   -27]])\n",
            "tensor([0.7754, 0.6890, 0.8013,  ..., 0.4954, 0.4954, 0.4954],\n",
            "       dtype=torch.float16)\n",
            "tensor(0.9971, dtype=torch.float16)\n",
            "tensor(0.0006, dtype=torch.float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(rank_diff, 'rank_diff.pt')\n",
        "torch.save(confidence, 'confidence.pt')"
      ],
      "metadata": {
        "id": "RmfhIOa7PuNK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_unclean = torch.load('logits_big.pt')\n",
        "small_unclean = torch.load('logits_small.pt')\n",
        "logits_large = torch.stack([large_unclean[i][0] for i in range(len(large_unclean))])\n",
        "logits_small = torch.stack([small_unclean[i][0] for i in range(len(small_unclean))])"
      ],
      "metadata": {
        "id": "Kzfp5cwoVqXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ca8141-8ef8-492f-949c-3c1b22860195"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-b54ae3309da7>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  large_unclean = torch.load('logits_big.pt')\n",
            "<ipython-input-19-b54ae3309da7>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  small_unclean = torch.load('logits_small.pt')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits_large)\n",
        "print(logits_small)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsLAvUjpdE47",
        "outputId": "beaeb660-72cb-4027-bbcb-27aaa0cf35d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        ...,\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf]])\n",
            "tensor([[  -inf,   -inf, 9.2500,  ...,   -inf,   -inf,   -inf],\n",
            "        [  -inf,   -inf,   -inf,  ...,   -inf,   -inf,   -inf],\n",
            "        [  -inf,   -inf,   -inf,  ...,   -inf,   -inf,   -inf],\n",
            "        ...,\n",
            "        [  -inf,   -inf, 8.6719,  ...,   -inf,   -inf,   -inf],\n",
            "        [  -inf,   -inf, 7.1367,  ...,   -inf,   -inf,   -inf],\n",
            "        [  -inf,   -inf, 8.7266,  ...,   -inf,   -inf,   -inf]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "smoothed_logits = smoothed_logits(confidence, logits_large, logits_small)\n",
        "torch.save(smoothed_logits, 'smoothed_logits.pt')"
      ],
      "metadata": {
        "id": "bByNMxrNWBzQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(smoothed_logits)\n",
        "print(smoothed_logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRoYzYi3epwY",
        "outputId": "4abbccd5-0576-4ddf-fbec-a09a23ed1d5b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        ...,\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf],\n",
            "        [-inf, -inf, -inf,  ..., -inf, -inf, -inf]])\n",
            "torch.Size([30, 32000])\n"
          ]
        }
      ]
    }
  ]
}